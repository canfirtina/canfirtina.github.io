---
---
@article{firtina_aphmm_2022,
  title = {ApHMM: Accelerating Profile Hidden Markov Models for Fast and Energy-Efficient Genome Analysis},
  copyright = {Creative Commons Attribution 4.0 International},
  journal = {arXiv},
  author = {Firtina, Can and Pillai, Kamlesh and Kalsi, Gurpreet S. and Suresh, Bharathwaj and Cali, Damla Senol and Kim, Jeremie and Shahroodi, Taha and Cavlak, Meryem Banu and Lindegger, Joel and Alser, Mohammed and Luna, Juan Gómez and Subramoney, Sreenivas and Mutlu, Onur},
  year = {2022},
  abstract = {Profile hidden Markov models (pHMMs) are widely used in many bioinformatics applications to accurately identify similarities between biological sequences (e.g., DNA or protein sequences). PHMMs use a commonly-adopted and highly-accurate method, called the Baum-Welch algorithm, to calculate these similarities. However, the Baum-Welch algorithm is computationally expensive, and existing works provide either software- or hardware-only solutions for a fixed pHMM design. When we analyze the state-of-the-art works, we find that there is a pressing need for a flexible, high-performant, and energy-efficient hardware-software co-design to efficiently and effectively solve all the major inefficiencies in the Baum-Welch algorithm for pHMMs.
  We propose ApHMM, the first flexible acceleration framework that can significantly reduce computational and energy overheads of the Baum-Welch algorithm for pHMMs. ApHMM leverages hardware-software co-design to solve the major inefficiencies in the Baum-Welch algorithm by 1) designing a flexible hardware to support different pHMMs designs, 2) exploiting the predictable data dependency pattern in an on-chip memory with memoization techniques, 3) quickly eliminating negligible computations with a hardware-based filter, and 4) minimizing the redundant computations. We implement our 1) hardware-software optimizations on a specialized hardware and 2) software optimizations for GPUs to provide the first flexible Baum-Welch accelerator for pHMMs. ApHMM provides significant speedups of 15.55x-260.03x, 1.83x-5.34x, and 27.97x compared to CPU, GPU, and FPGA implementations of the Baum-Welch algorithm, respectively. ApHMM outperforms the state-of-the-art CPU implementations of three important bioinformatics applications, 1) error correction, 2) protein family search, and 3) multiple sequence alignment, by 1.29x-59.94x, 1.03x-1.75x, and 1.03x-1.95x, respectively.},
  selected=true,
  montha={July},
  abbr={arXiv},
  bibtex_show=true,
  pdf={firtina_2022_arxiv_aphmm.pdf},
  code={https://github.com/CMU-SAFARI/ApHMM-GPU},
  url = {https://arxiv.org/abs/2207.09765},
  doi = {10.48550/ARXIV.2207.09765},
}

@inproceedings{cali_segram_2022,
  address = {New York, NY, USA},
  series = {{ISCA} '22},
  title = {{SeGraM}: {A} {Universal} {Hardware} {Accelerator} for {Genomic} {Sequence}-to-{Graph} and {Sequence}-to-{Sequence} {Mapping}},
  isbn = {978-1-4503-8610-4},
  url = {https://doi.org/10.1145/3470496.3527436},
  doi = {10.1145/3470496.3527436},
  abstract = {A critical step of genome sequence analysis is the mapping of sequenced DNA fragments (i.e., reads) collected from an individual to a known linear reference genome sequence (i.e., sequence-to-sequence mapping). Recent works replace the linear reference sequence with a graph-based representation of the reference genome, which captures the genetic variations and diversity across many individuals in a population. Mapping reads to the graph-based reference genome (i.e., sequence-to-graph mapping) results in notable quality improvements in genome analysis. Unfortunately, while sequence-to-sequence mapping is well studied with many available tools and accelerators, sequence-to-graph mapping is a more difficult computational problem, with a much smaller number of practical software tools currently available.We analyze two state-of-the-art sequence-to-graph mapping tools and reveal four key issues. We find that there is a pressing need to have a specialized, high-performance, scalable, and low-cost algorithm/hardware co-design that alleviates bottlenecks in both the seeding and alignment steps of sequence-to-graph mapping. Since sequence-to-sequence mapping can be treated as a special case of sequence-to-graph mapping, we aim to design an accelerator that is efficient for both linear and graph-based read mapping.To this end, we propose SeGraM, a universal algorithm/hardware co-designed genomic mapping accelerator that can effectively and efficiently support both sequence-to-graph mapping and sequence-to-sequence mapping, for both short and long reads. To our knowledge, SeGraM is the first algorithm/hardware co-design for accelerating sequence-to-graph mapping. SeGraM consists of two main components: (1) MinSeed, the first minimizer-based seeding accelerator, which finds the candidate locations in a given genome graph; and (2) BitAlign, the first bitvector-based sequence-to-graph alignment accelerator, which performs alignment between a given read and the subgraph identified by MinSeed. We couple SeGraM with high-bandwidth memory to exploit low latency and highly-parallel memory access, which alleviates the memory bottleneck.We demonstrate that SeGraM provides significant improvements for multiple steps of the sequence-to-graph (i.e., S2G) and sequence-to-sequence (i.e., S2S) mapping pipelines. First, SeGraM outperforms state-of-the-art S2G mapping tools by 5.9×/3.9× and 106×/- 742× for long and short reads, respectively, while reducing power consumption by 4.1×/4.4× and 3.0×/3.2×. Second, BitAlign outperforms a state-of-the-art S2G alignment tool by 41×-539× and three S2S alignment accelerators by 1.2×-4.8×. We conclude that SeGraM is a high-performance and low-cost universal genomics mapping accelerator that efficiently supports both sequence-to-graph and sequence-to-sequence mapping pipelines.},
  booktitle = {Proceedings of the 49th {Annual} {International} {Symposium} on {Computer} {Architecture}},
  publisher = {Association for Computing Machinery},
  author = {Cali, Damla Senol and Kanellopoulos, Konstantinos and Lindegger, Joël and Bingöl, Zülal and Kalsi, Gurpreet S. and Zuo, Ziyi and Firtina, Can and Cavlak, Meryem Banu and Kim, Jeremie and Ghiasi, Nika Mansouri and Singh, Gagandeep and Gómez-Luna, Juan and Alserr, Nour Almadhoun and Alser, Mohammed and Subramoney, Sreenivas and Alkan, Can and Ghose, Saugata and Mutlu, Onur},
  year = {2022},
  montha={June},
  slides={https://people.inf.ethz.ch/omutlu/pub/SeGraM_genomic-sequence-mapping-universal-accelerator_isca22-talk.pdf},
  pptx={https://people.inf.ethz.ch/omutlu/pub/SeGraM_genomic-sequence-mapping-universal-accelerator_isca22-talk.pptx},
  pages = {638--655},
  pdf={https://people.inf.ethz.ch/omutlu/pub/SeGraM_genomic-sequence-mapping-universal-accelerator_isca22.pdf},
  abbr={ISCA},
  bibtex_show=true,
}

@article{shahroodi_demeter_2022,
  title = {Demeter: {A} {Fast} and {Energy}-{Efficient} {Food} {Profiler} using {Hyperdimensional} {Computing} in {Memory}},
  copyright = {Creative Commons Attribution 4.0 International},
  url = {https://arxiv.org/abs/2206.01932},
  abstract = {Food profiling is an essential step in any food monitoring system needed to prevent health risks and potential frauds in the food industry. Significant improvements in sequencing technologies are pushing food profiling to become the main computational bottleneck. State-of-the-art profilers are unfortunately too costly for food profiling. 
Our goal is to design a food profiler that solves the main limitations of existing profilers, namely (1) working on massive data structures and (2) incurring considerable data movement, for a real-time monitoring system. To this end, we propose Demeter, the first platform-independent framework for food profiling. Demeter overcomes the first limitation through the use of hyperdimensional computing (HDC) and efficiently performs the accurate few-species classification required in food profiling. We overcome the second limitation by the use of an in-memory hardware accelerator for Demeter (named Acc-Demeter) based on memristor devices. Acc-Demeter actualizes several domain-specific optimizations and exploits the inherent characteristics of memristors to improve the overall performance and energy consumption of Acc-Demeter. 
We compare Demeter's accuracy with other industrial food profilers using detailed software modeling. We synthesize Acc-Demeter's required hardware using UMC's 65nm library by considering an accurate PCM model based on silicon-based prototypes. Our evaluations demonstrate that Acc-Demeter achieves a (1) throughput improvement of 192x and 724x and (2) memory reduction of 36x and 33x compared to Kraken2 and MetaCache (2 state-of-the-art profilers), respectively, on typical food-related databases. Demeter maintains an acceptable profiling accuracy (within 2\% of existing tools) and incurs a very low area overhead.},
  journal = {arXiv},
  author = {Shahroodi, Taha and Zahedi, Mahdi and Firtina, Can and Alser, Mohammed and Wong, Stephan and Mutlu, Onur and Hamdioui, Said},
  year = {2022},
  montha = {June},
  doi = {10.48550/ARXIV.2206.01932},
  pdf={https://arxiv.org/pdf/2206.01932.pdf},
  abbr={IEEE Access},
  bibtex_show=true,
}

@article{alser_molecules_2022,
  title = {From {Molecules} to {Genomic} {Variations}: {Accelerating} {Genome} {Analysis} via {Intelligent} {Algorithms} and {Architectures}},
  issn = {2001-0370},
  doi = {10.1016/j.csbj.2022.08.019},
  journal = {Computational and Structural Biotechnology Journal},
  author = {Alser, Mohammed and Lindegger, Joel and Firtina, Can and Almadhoun, Nour and Mao, Haiyu and Singh, Gagandeep and Gomez-Luna, Juan and Mutlu, Onur},
  montha = August,
  year = {2022},
  pdf={https://arxiv.org/pdf/2205.07957.pdf},
  abbr={CSBJ},
  bibtex_show=true,
}

@article{alser_packaging_2022,
  title = {Packaging, containerization, and virtualization of computational omics methods: {Advances}, challenges, and opportunities},
  copyright = {Creative Commons Attribution 4.0 International},
  url = {https://arxiv.org/abs/2203.16261},
  journal = {arXiv},
  abstract = {Omics software tools have reshaped the landscape of modern biology and become an essential component of biomedical research. The increasing dependence of biomedical scientists on these powerful tools creates a need for easier installation and greater usability. Packaging, virtualization, and containerization are different approaches to satisfy this need by wrapping omics tools in additional software that makes the omics tools easier to install and use. Here, we systematically review practices across prominent packaging, virtualization, and containerization platforms. We outline the challenges, advantages, and limitations of each approach and some of the most widely used platforms from the perspectives of users, software developers, and system administrators. We also propose principles to make packaging, virtualization, and containerization of omics software more sustainable and robust to increase the reproducibility of biomedical and life science research.},
  author = {Alser, Mohammed and Waymost, Sharon and Ayyala, Ram and Lawlor, Brendan and Abdill, Richard J. and Rajkumar, Neha and LaPierre, Nathan and Brito, Jaqueline and Ribeiro-dos-Santos, Andre M. and Firtina, Can and Almadhoun Alserr, Nour and Sarwal, Varuni and Eskin, Eleazar and Hu, Qiyang and Strong, Derek and Byoung-Do and {Kim} and Abedalthagafi, Malak S. and Mutlu, Onur and Mangul, Serghei},
  year = {2022},
  montha={March},
  doi = {10.48550/ARXIV.2203.16261},
  pdf={alser_2022_arxiv_packaging,_containerization,_and_virtualization_of_computational_omics_methods.pdf},
  abbr={arXiV},
  bibtex_show=true,
}

@inproceedings{mansouri_ghiasi_genstore_2022,
  address = {New York, NY, USA},
  series = {{ASPLOS} 2022},
  title = {{GenStore}: {A} {High}-{Performance} in-{Storage} {Processing} {System} for {Genome} {Sequence} {Analysis}},
  copyright = {All rights reserved},
  isbn = {978-1-4503-9205-1},
  url = {https://doi.org/10.1145/3503222.3507702},
  confurl = {https://asplos-conference.org/2022/},
  doi = {10.1145/3503222.3507702},
  abstract = {Read mapping is a fundamental step in many genomics applications. It is used to identify potential matches and differences between fragments (called reads) of a sequenced genome and an already known genome (called a reference genome). Read mapping is costly because it needs to perform approximate string matching (ASM) on large amounts of data. To address the computational challenges in genome analysis, many prior works propose various approaches such as accurate filters that select the reads within a dataset of genomic reads (called a read set) that must undergo expensive computation, efficient heuristics, and hardware acceleration. While effective at reducing the amount of expensive computation, all such approaches still require the costly movement of a large amount of data from storage to the rest of the system, which can significantly lower the end-to-end performance of read mapping in conventional and emerging genomics systems. We propose GenStore, the first in-storage processing system designed for genome sequence analysis that greatly reduces both data movement and computational overheads of genome sequence analysis by exploiting low-cost and accurate in-storage filters. GenStore leverages hardware/software co-design to address the challenges of in-storage processing, supporting reads with 1)\&nbsp;different properties such as read lengths and error rates, which highly depend on the sequencing technology, and 2)\&nbsp;different degrees of genetic variation compared to the reference genome, which highly depends on the genomes that are being compared. Through rigorous analysis of read mapping processes of reads with different properties and degrees of genetic variation, we meticulously design low-cost hardware accelerators and data/computation flows inside a NAND flash-based solid-state drive (SSD). Our evaluation using a wide range of real genomic datasets shows that GenStore, when implemented in three modern NAND flash-based SSDs, significantly improves the read mapping performance of state-of-the-art software (hardware) baselines by 2.07-6.05× (1.52-3.32×) for read sets with high similarity to the reference genome and 1.45-33.63× (2.70-19.2×) for read sets with low similarity to the reference genome.},
  booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
  publisher = {Association for Computing Machinery},
  author = {Mansouri Ghiasi, Nika and Park, Jisung and Mustafa, Harun and Kim, Jeremie and Olgun, Ataberk and Gollwitzer, Arvid and Senol Cali, Damla and Firtina, Can and Mao, Haiyu and Almadhoun Alserr, Nour and Ausavarungnirun, Rachata and Vijaykumar, Nandita and Alser, Mohammed and Mutlu, Onur},
  year = {2022},
  montha={March},
  keywords = {Genomics, Filtering, Near-Data Processing, Read Mapping, Storage},
  pages = {635--654},
  pdf={mansouri_ghiasi_2022_association_for_computing_machinery_genstore.pdf},
  code={https://github.com/CMU-SAFARI/GenStore},
  abbr={ASPLOS},
  slides={https://people.inf.ethz.ch/omutlu/pub/GenStore_asplos22-talk.pdf},
  pptx={https://people.inf.ethz.ch/omutlu/pub/GenStore_asplos22-talk.pptx},
  video={https://www.youtube.com/watch?v=bv7hgXOOMjk},
  bibtex_show=true,
}

@article{kim_fastremap_2022,
  title = {{FastRemap}: {A} {Tool} for {Quickly} {Remapping} {Reads} between {Genome} {Assemblies}},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btac554},
  journal = {Bioinformatics},
  author = {Kim, Jeremie S and Firtina, Can and Cavlak, Meryem Banu and Senol Cali, Damla and Alkan, Can and Mutlu, Onur},
  month = aug,
  year = {2022},
  pages = {btac554},
  montha={August},
  pdf={kim_2022_arxiv_fastremap.pdf},
  code={https://github.com/CMU-SAFARI/FastRemap},
  abbr={Bioinformatics},
  bibtex_show=true,
}

@article{firtina_blend_2021,
  title = {{BLEND}: {A} {Fast}, {Memory}-{Efficient}, and {Accurate} {Mechanism} to {Find} {Fuzzy} {Seed} {Matches}},
  copyright = {All rights reserved},
  url = {https://doi.org/10.48550/ARXIV.2112.08687},
  journal = {arXiv},
  abstract = {Generating the hash values of short subsequences, called seeds, enables quickly identifying similarities between genomic sequences by matching seeds with a single lookup of their hash values. However, these hash values can be used only for finding exact-matching seeds as the conventional hashing methods assign distinct hash values for different seeds, including highly similar seeds. Finding only exact-matching seeds causes either 1) increasing the use of the costly sequence alignment or 2) limited sensitivity.
  We introduce BLEND, the first efficient and accurate mechanism that can identify both exact-matching and highly similar seeds with a single lookup of their hash values, called fuzzy seeds matches. BLEND 1) utilizes a technique called SimHash, that can generate the same hash value for similar sets, and 2) provides the proper mechanisms for using seeds as sets with the SimHash technique to find fuzzy seed matches efficiently.
  We show the benefits of BLEND when used in read overlapping and read mapping. For read overlapping, BLEND is faster by 2.6x-63.5x (on average 19.5x), has a lower memory footprint by 0.9x-9.7x (on average 3.6x), and finds higher quality overlaps leading to accurate de novo assemblies than the state-of-the-art tool, minimap2. For read mapping, BLEND is faster by 0.7x-3.7x (on average 1.7x) than minimap2. Source code is available at https://github.com/CMU-SAFARI/BLEND.},
  author = {Firtina, Can and Park, Jisung and Alser, Mohammed and Kim, Jeremie S. and Senol Cali, Damla and Shahroodi, Taha and Ghiasi, Nika Mansouri and Singh, Gagandeep and Kanellopoulos, Konstantinos and Alkan, Can and Mutlu, Onur},
  year = {2021},
  montha={December},
  doi = {10.48550/ARXIV.2112.08687},
  selected=true,
  pdf={firtina_2021_arxiv_blend.pdf},
  code={https://github.com/CMU-SAFARI/BLEND},
  abbr={arXiv},
  bibtex_show=true,
}

@article{onural_modeling_2021,
  title = {Modeling {Economic} {Activities} and {Random} {Catastrophic} {Failures} of {Financial} {Networks} via {Gibbs} {Random} {Fields}},
  volume = {58},
  issn = {1572-9974},
  url = {https://doi.org/10.1007/s10614-020-10023-3},
  doi = {10.1007/s10614-020-10023-3},
  abstract = {The complicated economic behavior of entities in a population can be modeled as a Gibbs random field (GRF). Even with simple GRF models, which restrict direct statistical interactions with a small number of neighbors of an entity, real life economic and financial activities may be effectively described. A computer simulator is developed to run empirical experiments to assess different coupling structures and parameters of the presented model; it is possible to test many economic and financial models and policies in terms of their transient and steady-state consequences.},
  number = {2},
  journal = {Computational Economics},
  author = {Onural, Levent and Pınar, Mustafa Çelebi and Firtina, Can},
  montha={August},
  year = {2021},
  pages = {203--232},
  pdf={onural_2021_modeling_economic_activities_and_random_catastrophic_failures_of_financial.pdf},
  bibtex_show=true,
}

@article{kim_airlift_2021,
  title = {{AirLift}: {A} {Fast} and {Comprehensive} {Technique} for {Remapping} {Alignments} between {Reference} {Genomes}},
  copyright = {All rights reserved},
  url = {http://biorxiv.org/content/early/2021/02/17/2021.02.16.431517.abstract},
  doi = {10.1101/2021.02.16.431517},
  abstract = {As genome sequencing tools and techniques improve, researchers are able to incrementally assemble more accurate reference genomes, which enable sensitivity in read mapping and downstream analysis such as variant calling. A more sensitive downstream analysis is critical for a better understanding of the genome donor (e.g., health characteristics). Therefore, read sets from sequenced samples should ideally be mapped to the latest available reference genome that represents the most relevant population. Unfortunately, the increasingly large amount of available genomic data makes it prohibitively expensive to fully re-map each read set to its respective reference genome every time the reference is updated. There are several tools that attempt to accelerate the process of updating a read data set from one reference to another (i.e., remapping) by 1) identifying regions that appear similarly between two references and 2) updating the mapping location of reads that map to any of the identified regions in the old reference to the corresponding similar region in the new reference. The main drawback of existing approaches is that if a read maps to a region in the old reference that does not appear with a reasonable degree of similarity in the new reference, the read cannot be remapped. We find that, as a result of this drawback, a significant portion of annotations (i.e., coding regions in a genome) are lost when using state-of-the-art remapping tools. To address this major limitation in existing tools, we propose AirLift, a fast and comprehensive technique for remapping alignments from one genome to another. Compared to the state-of-the-art method for remapping reads (i.e., full mapping), AirLift reduces 1) the number of reads (out of the entire read set) that need to be fully mapped to the new reference by up to 99.99\% and 2) the overall execution time to remap read sets between two reference genome versions by 6.7×, 6.6×, and 2.8× for large (human), medium (C. elegans), and small (yeast) reference genomes, respectively. We validate our remapping results with GATK and find that AirLift provides similar accuracy in identifying ground truth SNP and INDEL variants as the baseline of fully mapping a read set.Code Availability AirLift source code and readme describing how to reproduce our results are available at https://github.com/CMU-SAFARI/AirLift.Competing Interest StatementThe authors have declared no competing interest.},
  journal = {bioRxiv},
  author = {Kim, Jeremie S. and Firtina, Can and Cavlak, Meryem Banu and Cali, Damla Senol and Hajinazar, Nastaran and Alser, Mohammed and Alkan, Can and Mutlu, Onur},
  month = {January},
  year = {2021},
  pages = {2021.02.16.431517},
  selected=true,
  pdf={kim_2019_arxiv_airlift.pdf},
  code={https://github.com/CMU-SAFARI/AirLift},
  abbr={bioRxiv},
  bibtex_show=true,
}

@inproceedings{cali_genasm_2020,
  address = {Virtual},
  title = {{GenASM}: {A} {High}-{Performance}, {Low}-{Power} {Approximate} {String} {Matching} {Acceleration} {Framework} for {Genome} {Sequence} {Analysis}},
  copyright = {All rights reserved},
  url = {https://ieeexplore.ieee.org/document/9251930},
  confurl = {https://www.microarch.org/micro53/},
  doi = {10.1109/MICRO50266.2020.00081},
  abstract = {Genome sequence analysis has enabled significant advancements in medical and scientific areas such as personalized medicine, outbreak tracing, and the understanding of evolution. To perform genome sequencing, devices extract small random fragments of an organism's DNA sequence (known as reads). The first step of genome sequence analysis is a computational process known as read mapping. In read mapping, each fragment is matched to its potential location in the reference genome with the goal of identifying the original location of each read in the genome. Unfortunately, rapid genome sequencing is currently bottlenecked by the computational power and memory bandwidth limitations of existing systems, as many of the steps in genome sequence analysis must process a large amount of data. A major contributor to this bottleneck is approximate string matching (ASM), which is used at multiple points during the mapping process. ASM enables read mapping to account for sequencing errors and genetic variations in the reads. We propose GenASM, the first ASM acceleration framework for genome sequence analysis. GenASM performs bitvectorbased ASM, which can efficiently accelerate multiple steps of genome sequence analysis. We modify the underlying ASM algorithm (Bitap) to significantly increase its parallelism and reduce its memory footprint. Using this modified algorithm, we design the first hardware accelerator for Bitap. Our hardware accelerator consists of specialized systolic-array-based compute units and on-chip SRAMs that are designed to match the rate of computation with memory capacity and bandwidth, resulting in an efficient design whose performance scales linearly as we increase the number of compute units working in parallel. We demonstrate that GenASM provides significant performance and power benefits for three different use cases in genome sequence analysis. First, GenASM accelerates read alignment for both long reads and short reads. For long reads, GenASM outperforms state-of-the-art software and hardware accelerators by 116× and 3.9×, respectively, while reducing power consumption by 37× and 2.7×. For short reads, GenASM outperforms state-of-the-art software and hardware accelerators by 111× and 1.9×. Second, GenASM accelerates pre-alignment filtering for short reads, with 3.7× the performance of a state-of-the-art pre-alignment filter, while reducing power consumption by 1.7× and significantly improving the filtering accuracy. Third, GenASM accelerates edit distance calculation, with 22-12501× and 9.3-400× speedups over the state-of-the-art software library and FPGA-based accelerator, respectively, while reducing power consumption by 548-582× and 67×. We conclude that GenASM is a flexible, high-performance, and low-power framework, and we briefly discuss four other use cases that can benefit from GenASM.},
  booktitle = {Proceedings of the 53rd {International} {Symposium} on {Microarchitecture}},
  author = {Senol Cali, Damla and Kalsi, Gurpreet S. and Bingöl, Zülal and Firtina, Can and Subramanian, Lavanya and Kim, Jeremie S. and Ausavarungnirun, Rachata and Alser, Mohammed and G{\'o}mez-Luna, Juan and Boroumand, Amirali and Norion, Anant and Scibisz, Allison and Subramoney, Sreenivas and Alkan, Can and Ghose, Saugata and Mutlu, Onur},
  year = {2020},
  montha={October},
  pages = {951--966},
  pdf={cali_2020_genasm.pdf},
  code={https://github.com/CMU-SAFARI/GenASM},
  abbr={MICRO},
  slides={https://people.inf.ethz.ch/omutlu/pub/GenASM-approximate-string-matching-framework-for-genome-analysis_micro20-talk.pdf},
  pptx={https://people.inf.ethz.ch/omutlu/pub/GenASM-approximate-string-matching-framework-for-genome-analysis_micro20-talk.pptx},
  video={http://www.youtube.com/watch?v=XoLpzmN-Pas},
  bibtex_show=true,
}

@article{firtina_apollo_2020,
  title = {Apollo: a sequencing-technology-independent, scalable and accurate assembly polishing algorithm},
  volume = {36},
  issn = {1367-4803},
  url = {https://doi.org/10.1093/bioinformatics/btaa179},
  doi = {10.1093/bioinformatics/btaa179},
  abstract = {Third-generation sequencing technologies can sequence long reads that contain as many as 2 million base pairs. These long reads are used to construct an assembly (i.e. the subject’s genome), which is further used in downstream genome analysis. Unfortunately, third-generation sequencing technologies have high sequencing error rates and a large proportion of base pairs in these long reads is incorrectly identified. These errors propagate to the assembly and affect the accuracy of genome analysis. Assembly polishing algorithms minimize such error propagation by polishing or fixing errors in the assembly by using information from alignments between reads and the assembly (i.e. read-to-assembly alignment information). However, current assembly polishing algorithms can only polish an assembly using reads from either a certain sequencing technology or a small assembly. Such technology-dependency and assembly-size dependency require researchers to (i) run multiple polishing algorithms and (ii) use small chunks of a large genome to use all available readsets and polish large genomes, respectively.We introduce Apollo, a universal assembly polishing algorithm that scales well to polish an assembly of any size (i.e. both large and small genomes) using reads from all sequencing technologies (i.e. second- and third-generation). Our goal is to provide a single algorithm that uses read sets from all available sequencing technologies to improve the accuracy of assembly polishing and that can polish large genomes. Apollo (i) models an assembly as a profile hidden Markov model (pHMM), (ii) uses read-to-assembly alignment to train the pHMM with the Forward–Backward algorithm and (iii) decodes the trained model with the Viterbi algorithm to produce a polished assembly. Our experiments with real readsets demonstrate that Apollo is the only algorithm that (i) uses reads from any sequencing technology within a single run and (ii) scales well to polish large assemblies without splitting the assembly into multiple parts. Source code is available at https://github.com/CMU-SAFARI/Apollo. Supplementary data are available at Bioinformatics online.},
  number = {12},
  urldate = {2022-04-13},
  journal = {Bioinformatics},
  author = {Firtina, Can and Kim, Jeremie S. and Alser, Mohammed and Senol Cali, Damla and Cicek, A Ercument and Alkan, Can and Mutlu, Onur},
  montha={June},
  year = {2020},
  pages = {3669--3679},
  selected=true,
  pdf={firtina_2020_apollo.pdf},
  code={https://github.com/CMU-SAFARI/Apollo},
  abbr={Bioinformatics},
  bibtex_show=true,
}

@article{firtina_hercules_2018,
  title = {Hercules: a profile {HMM}-based hybrid error correction algorithm for long reads},
  volume = {46},
  issn = {0305-1048},
  url = {https://doi.org/10.1093/nar/gky724},
  doi = {10.1093/nar/gky724},
  abstract = {Choosing whether to use second or third generation sequencing platforms can lead to trade-offs between accuracy and read length. Several types of studies require long and accurate reads. In such cases researchers often combine both technologies and the erroneous long reads are corrected using the short reads. Current approaches rely on various graph or alignment based techniques and do not take the error profile of the underlying technology into account. Efficient machine learning algorithms that address these shortcomings have the potential to achieve more accurate integration of these two technologies. We propose Hercules, the first machine learning-based long read error correction algorithm. Hercules models every long read as a profile Hidden Markov Model with respect to the underlying platform’s error profile. The algorithm learns a posterior transition/emission probability distribution for each long read to correct errors in these reads. We show on two DNA-seq BAC clones (CH17-157L1 and CH17-227A2) that Hercules-corrected reads have the highest mapping rate among all competing algorithms and have the highest accuracy when the breadth of coverage is high. On a large human CHM1 cell line WGS data set, Hercules is one of the few scalable algorithms; and among those, it achieves the highest accuracy.},
  number = {21},
  urldate = {2022-04-13},
  journal = {Nucleic Acids Research},
  author = {Firtina, Can and Bar-Joseph, Ziv and Alkan, Can and Cicek, A. Ercument},
  montha={November},
  year = {2018},
  pages = {e125--e125},
  pdf={firtina_2018_hercules.pdf},
  code={https://github.com/BilkentCompGen/hercules},
  abbr={NAR},
  bibtex_show=true,
}

@article{otlu_glanet_2017,
  title = {{GLANET}: genomic loci annotation and enrichment tool},
  volume = {33},
  copyright = {All rights reserved},
  issn = {1367-4803},
  url = {https://doi.org/10.1093/bioinformatics/btx326},
  doi = {10.1093/bioinformatics/btx326},
  abstract = {Genomic studies identify genomic loci representing genetic variations, transcription factor (TF) occupancy, or histone modification through next generation sequencing (NGS) technologies. Interpreting these loci requires evaluating them with known genomic and epigenomic annotations.We present GLANET as a comprehensive annotation and enrichment analysis tool which implements a sampling-based enrichment test that accounts for GC content and/or mappability biases, jointly or separately. GLANET annotates and performs enrichment analysis on these loci with a rich library. We introduce and perform novel data-driven computational experiments for assessing the power and Type-I error of its enrichment procedure which show that GLANET has attained high statistical power and well-controlled Type-I error rate. As a key feature, users can easily extend its library with new gene sets and genomic intervals. Other key features include assessment of impact of single nucleotide variants (SNPs) on TF binding sites and regulation based pathway enrichment analysis.GLANET can be run using its GUI or on command line. GLANET’s source code is available at https://github.com/burcakotlu/GLANET. Tutorials are provided at https://glanet.readthedocs.org.Supplementary data are available at Bioinformatics online.},
  number = {18},
  journal = {Bioinformatics},
  author = {Otlu, Burçak and Firtina, Can and Keleş, Sündüz and Tastan, Oznur},
  montha={September},
  year = {2017},
  pages = {2818--2828},
  pdf={otlu_2017_glanet.pdf},
  code={https://github.com/burcakotlu/GLANET},
  abbr={Bioinformatics},
  bibtex_show=true,
}

@article{firtina_genomic_2016,
  title = {On genomic repeats and reproducibility},
  volume = {32},
  issn = {1367-4803},
  url = {https://doi.org/10.1093/bioinformatics/btw139},
  doi = {10.1093/bioinformatics/btw139},
  abstract = {Results: Here, we present a comprehensive analysis on the reproducibility of computational characterization of genomic variants using high throughput sequencing data. We reanalyzed the same datasets twice, using the same tools with the same parameters, where we only altered the order of reads in the input (i.e. FASTQ file). Reshuffling caused the reads from repetitive regions being mapped to different locations in the second alignment, and we observed similar results when we only applied a scatter/gather approach for read mapping—without prior shuffling. Our results show that, some of the most common variation discovery algorithms do not handle the ambiguous read mappings accurately when random locations are selected. In addition, we also observed that even when the exact same alignment is used, the GATK HaplotypeCaller generates slightly different call sets, which we pinpoint to the variant filtration step. We conclude that, algorithms at each step of genomic variation discovery and characterization need to treat ambiguous mappings in a deterministic fashion to ensure full replication of results.},
  number = {15},
  journal = {Bioinformatics},
  author = {Firtina, Can and Alkan, Can},
  montha={August},
  year = {2016},
  pages = {2243--2247},
  pdf={firtina_2016_on_genomic_repeats_and_reproducibility.pdf},
  code={https://zenodo.org/record/32611#.YmcGgy8RqPw},
  abbr={Bioinformatics},
  bibtex_show=true,
}
